library(readxl)
library(cluster)
library(factoextra)
library(flexclust)
library(fpc)
library(clustertend)
library(ClusterR)
data <- read_excel("kk.xlsx", col_types = c("numeric", "numeric", "text", "numeric", "text", "text", "text", "numeric", "numeric", "text", "text", "numeric", "numeric", "numeric", "text", "text", "text", "text", "text", "numeric", "numeric", "text", "numeric", "numeric", "numeric"))
dim(data)
#Reactions and Potential because meaningfull clusters can be done
clusts<-kk[,c("Reactions","Potential")]
#our assamption to do 3 clusters because
km1 <- kmeans(clusts, 3)
km1
km1$cluster
#let's see how it will look like on graph
plot(clusts, col = km1$cluster, pch=".", cex=3)
points(km1$centers, col = 1:5, pch = 8, cex=2, lwd=2)
#or with more elipses
fviz_cluster(list(data=clusts, cluster=km1$cluster), ellipse.type="norm", geom="point", stand=FALSE, palette="jco", ggtheme=theme_classic()) #factoextra::
#also we can use PAM method
pams<-pam(clusts,3)
summary(pams)
#let's look on the graph
fviz_cluster(pams, geom = "point", ellipse.type = "convex")
#let's use clara method
claras<-eclust(clusts, "clara", k=3)
summary(claras)
fviz_cluster(claras)
fviz_silhouette(claras)
#clusters are simmiliar
#let's check how many clusters are proposed by R
fviz_nbclust(clusts,FUNcluster=pam) # factoextra::
fviz_nbclust(clusts, clara, method = "silhouette")+ theme_classic() # factoextra::
#it is shown that  the best is 2 clusters, but by our assumptions we decedided to use 3 clusters
# we can see that after 3 clusters the change in average silouthe width is minimal
install.packages("NbClust")
library(NbClust)
#second method by NbClust
nbbest<-NbClust(clusts, distance="euclidean", min.nc=2, max.nc=7, method="complete", index="ch")
nbbest
nbbest$All.index
nbbest$Best.nc
nbbest$Best.partition
#third method
wss <- (nrow(clusts)-1)*sum(apply(clusts,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(clusts,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
# quality of clustering for k-means
km1<-kmeans(clusts, 2) # stats::
round(calinhara(clusts,km1$cluster),digits=2)
km2<-kmeans(clusts, 3) # stats::
round(calinhara(clusts,km2$cluster),digits=2)
km3<-kmeans(clusts, 4) # stats::
round(calinhara(clusts,km2$cluster),digits=2)
# so it is better to use 3 not 2 clusters
#postdiagnostic
post<-kmeansruns(clusts,krange=2:5,criterion="ch", iter.max=2, runs=2, scaledata=FALSE, alpha=0.001, critout=FALSE, plot=TRUE)
post
# so post diagnostic chose 2 clusters
library(dplyr)
# Also we can use Ward Hierarchical Clustering
d <- dist(clusts, method = "euclidean")
fit <- hclust(d, method="ward")
plot(fit)
groups <- cutree(fit, k=3)
rect.hclust(fit, k=3, border="red")
#so from dendogram we can see that meaningflly we can divide our data to 2 or 3 or 4 clusters
library(readxl)
library(cluster)
library(factoextra)
library(flexclust)
library(fpc)
library(clustertend)
library(ClusterR)
data <- read_excel("kk.xlsx", col_types = c("numeric", "numeric", "text", "numeric", "text", "text", "text", "numeric", "numeric", "text", "text", "numeric", "numeric", "numeric", "text", "text", "text", "text", "text", "numeric", "numeric", "text", "numeric", "numeric", "numeric"))
dim(data)
#Reactions and Potential because meaningfull clusters can be done
clusts<-kk[,c("Reactions","Potential")]
#our assamption to do 3 clusters because
km1 <- kmeans(clusts, 3)
km1
km1$cluster
#let's see how it will look like on graph
plot(clusts, col = km1$cluster, pch=".", cex=3)
points(km1$centers, col = 1:5, pch = 8, cex=2, lwd=2)
#or with more elipses
fviz_cluster(list(data=clusts, cluster=km1$cluster), ellipse.type="norm", geom="point", stand=FALSE, palette="jco", ggtheme=theme_classic()) #factoextra::
#also we can use PAM method
pams<-pam(clusts,3)
summary(pams)
#let's look on the graph
fviz_cluster(pams, geom = "point", ellipse.type = "convex")
#let's use clara method
claras<-eclust(clusts, "clara", k=3)
summary(claras)
fviz_cluster(claras)
fviz_silhouette(claras)
#clusters are simmiliar
#let's check how many clusters are proposed by R
fviz_nbclust(clusts,FUNcluster=pam) # factoextra::
fviz_nbclust(clusts, clara, method = "silhouette")+ theme_classic() # factoextra::
#it is shown that  the best is 2 clusters, but by our assumptions we decedided to use 3 clusters
# we can see that after 3 clusters the change in average silouthe width is minimal
install.packages("NbClust")
library(NbClust)
#second method by NbClust
nbbest<-NbClust(clusts, distance="euclidean", min.nc=2, max.nc=7, method="complete", index="ch")
nbbest
nbbest$All.index
nbbest$Best.nc
nbbest$Best.partition
#third method
wss <- (nrow(clusts)-1)*sum(apply(clusts,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(clusts,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
# quality of clustering for k-means
km1<-kmeans(clusts, 2) # stats::
round(calinhara(clusts,km1$cluster),digits=2)
km2<-kmeans(clusts, 3) # stats::
round(calinhara(clusts,km2$cluster),digits=2)
km3<-kmeans(clusts, 4) # stats::
round(calinhara(clusts,km2$cluster),digits=2)
# so it is better to use 3 not 2 clusters
#postdiagnostic
post<-kmeansruns(clusts,krange=2:5,criterion="ch", iter.max=2, runs=2, scaledata=FALSE, alpha=0.001, critout=FALSE, plot=TRUE)
post
# so post diagnostic chose 2 clusters
library(dplyr)
# Also we can use Ward Hierarchical Clustering
d <- dist(clusts, method = "euclidean")
fit <- hclust(d, method="ward")
plot(fit)
groups <- cutree(fit, k=3)
rect.hclust(fit, k=3, border="red")
#so from dendogram we can see that meaningflly we can divide our data to 2 or 3 or 4 clusters
install.packages("NbClust")
install.packages("jpeg")
install.packages("factoextra")
install.packages("gridExtra")
install.packages("factoextra")
photo <- system.file('fire.jpg',package='imager')
install.packages("jpeg")
install.packages("ggplot2")
library(ggplot2)
library(jpeg)
library(factoextra)
library(gridExtra)
kmeansResult <- kmeans(photo[], centers=2)
result <- raster(photo[[1]])
result <- setValues(result, kMeansResult$cluster)
kmeansResult <- kmeans(image[], centers=2)
library(dplyr)
library(raster)
source('D:/R and R Studio/Clustering.project/photo.clustering.R')
install.packages("ggplot2")
if(!"raster" %in% rownames(installed.packages())){install.packages("raster")}
library(raster)
photo <- system.file('fire.jpg',package='imager')
kmeansResult <- kmeans(image[], centers=2)
kmeans Result <- kmeans(image[], centers=2)
result <- raster(photo[[1]])
kmeansResult <- kmeans(photo[], centers=2)
result <- raster(image[[1]])
kMeansResult <- kmeans(image[], centers=6)
kMeansResult <- kmeans(photo[], centers=6)
results <- kmeans(m_norm,25)
